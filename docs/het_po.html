<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>HTE</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">IN4402</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Aplica</a>
</li>
<li>
  <a href="2SLS.html">2SLS</a>
</li>
<li>
  <a href="cart.html">CART</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">HTE</h1>

</div>


<style type="text/css">
.main-container {
  max-width: 90%;
  margin-left: auto;
  margin-right: auto;
}
body {
  text-align: justify;
}
</style>
<div id="introducción" class="section level1">
<h1><strong>1. Introducción</strong></h1>
<div id="objetivo" class="section level2">
<h2>Objetivo</h2>
<p>El objetivo de este módulo es proponer un caso que puedas analizar en tu propio computador.</p>
</div>
<div id="caso-percepciones-sobre-el-gasto-público-y-el-estado-de-bienestar" class="section level2">
<h2>Caso: percepciones sobre el gasto público y el Estado de Bienestar</h2>
<p>Los datos provienen de la base de datos “welfare” del artículo de Green &amp; Kern (2012). La Encuesta Social General (GSS, por sus siglas en inglés) es una encuesta comúnmente utilizada en Estados Unidos, la cual presenta efectos experimentales altamente replicados y una muestra suficientemente grande para ser analizada adecuadamente.</p>
<p>La base de datos evalúa las percepciones que tienen los estadounidenses sobre programas de gobierno que se alineen al denominado “Estado de Bienestar” (“welfare”), puesto que existe un prejuicio generalizado hacia programas y beneficios sociales. Un experimento conocido sobre esta encuesta asigna aleatoriamente a los respondentes a una evaluación de si el gasto público es “demasiado alto”, “adecuado” o “demasiado bajo”, en determinados programas. La condición experimental varía una única palabra en el fraseo de uno de los programas sociales: el tratamiento consiste en utilizar la palabra “bienestar” en vez de la frase “asistencia a los pobres” (welfare/assistance to the poor).</p>
<p>Los resultados de numerosos análisis de esta encuesta, desde 1986 hasta 2010, muestran que al ser expuestos al fraseo del programa como “bienestar social” (welfare), los encuestados muestran una probabilidad de 30% y 50% más de responder que el gasto es “demasiado alto” (too much). Algunas de las razones expuestas para explicar estas diferencias se basan en estereotipos generalizados sobre los beneficiarios de los programas de bienestar y de la gente más pobre, particularmente en estereotipos raciales; también se esgrimen argumentos sobre orientaciones político-ideológicas sobre individualismo y conservadurismo.</p>
<p>El estudio que se busca replicar en este tutorial estudia la heterogeneidad de dicho tratamiento.</p>
</div>
<div id="datos" class="section level2">
<h2>Datos</h2>
<p>La base de datos puedes descargarla <a href="https://github.com/AndyFerver/IN4402/blob/2a00eecd73f963c62dd18c9e726f09b61df36988/welfarelabel.rar">aquí</a>, y si necesitas descargar este tutorial en formato Rmd para verlo en tu computador de manera offline, puedes hacerlo desde <a href="https://github.com/AndyFerver/IN4402/blob/1b224508b213f0699491a9d3683f092b593b21b9/het_po.rar">aquí</a>.</p>
<div id="green-d.-p.-kern-h.-l.-2012.-modeling-heterogeneous-treatment-effects-in-survey-experiments-with-bayesian-additive-regression-trees.-public-opinion-quarterly-763-491-511." class="section level6">
<h6>Green, D. P., &amp; Kern, H. L. (2012). Modeling heterogeneous treatment effects in survey experiments with Bayesian additive regression trees. Public opinion quarterly, 76(3), 491-511.</h6>
</div>
<div id="este-tutorial-es-una-adaptación-del-tutorial-estimation-of-heterogeneous-treatment-effects-realizado-por-athey-wager-hadad-klosin-muhelbach-nie-y-schaelling-en-mayo-de-2020-para-su-curso-de-machine-learning-and-causal-inference." class="section level6">
<h6>Este tutorial es una adaptación del tutorial “Estimation of Heterogeneous Treatment Effects” realizado por Athey, Wager, Hadad, Klosin, Muhelbach, Nie y Schaelling en mayo de 2020 para su curso de “Machine Learning and Causal Inference”.</h6>
</div>
</div>
</div>
<div id="inicio" class="section level1">
<h1><strong>2. Inicio</strong></h1>
<div id="cargar-las-librerías-en-r" class="section level2">
<h2>Cargar las librerías en R</h2>
<p>Comience cargando las librerías que usaremos en este tutorial. A ellas debe agregarles las tradicionales usadas para cargar la base de datos y algunas de manejo básico de bases.</p>
<pre class="r"><code>library(fBasics)
library(grf)
library(ggplot2)
library(estimatr)
library(dplyr)</code></pre>
</div>
<div id="preparar-los-datos" class="section level2">
<h2>Preparar los datos</h2>
<p>Limpiaremos de datos faltantes, y botaremos aquellas columnas que no sean variables de resultado, de tratamiento o covariables.</p>
<pre class="r"><code>df &lt;- read_csv(&quot;welfarelabel.csv&quot;)
df &lt;- na.omit(df)
df &lt;- df %&gt;% select(-c(&quot;id&quot;, &quot;_merge&quot;))</code></pre>
<p>Puede ser una buena práctica cambiar el nombre de las variables, para utilidad posterior. Como utilizaremos funciones recientes de Causal Trees y Causal Random Forests, propuestas por Athey y otros, estas todavía no aceptan datos categorizados como “factor”, por lo que es recomebdable transformarlos a “numeric”. Para esto último utilizaremos las funciones <em>lapply()</em> y <em>as.numeric()</em>.</p>
<pre class="r"><code>df &lt;- df %&gt;% rename(Y=y,W=w)
df &lt;- data.frame(lapply(df, function(x) as.numeric(as.character(x))))</code></pre>
</div>
</div>
<div id="descriptivos" class="section level1">
<h1><strong>3. Descriptivos</strong></h1>
<p>Comenzaremos el análisis echando una mirada al contenido de la base de datos. Para ello, veremos los estadísticos descriptivos de las variables. Para eso, puede utilizar las funciones de la librería <strong>fBasics</strong>, la cual debe estar instalada para poder usarse.</p>
<pre class="r"><code># Hacemos una matriz con los estadísticos
summ_stats &lt;- fBasics::basicStats(df)
summ_stats &lt;- as.data.frame(t(summ_stats))

# Le ponemos títulos a la matriz para facilitar la lectura
summ_stats &lt;- summ_stats[c(&quot;Mean&quot;, &quot;Stdev&quot;, &quot;Minimum&quot;, &quot;1. Quartile&quot;, &quot;Median&quot;,  &quot;3. Quartile&quot;, &quot;Maximum&quot;)] %&gt;% 
  rename(&quot;Lower quartile&quot; = &#39;1. Quartile&#39;, &quot;Upper quartile&quot;= &quot;3. Quartile&quot;)

summ_stats</code></pre>
<p>Se dejará un 20% de la muestra para validación, y se utilizará el 80% de los datos para entrenar los árboles.</p>
<pre class="r"><code>train_fraction &lt;- 0.80
n &lt;- dim(df)[1]
train_idx &lt;- sample.int(n, replace=F, size=floor(n*train_fraction))
df_train &lt;- df[train_idx,]
df_test &lt;- df[-train_idx,]</code></pre>
<p>¿Cuál es la proporción de individuos tratados en la muestra? (50%)</p>
</div>
<div id="estimando-heterogeneidad" class="section level1">
<h1><strong>4. Estimando Heterogeneidad</strong></h1>
<p>Para estimar el Random Forest utilizamos la función <em>causal_forest</em> del paquete <em>grf</em>. Debemos indicar cuáles son las covariables, la variable de resultado y la variable de tratamiento. Para esto primero definimos tales variables.</p>
<blockquote>
<p>De acuerdo a Athey, un buen número de árboles a utilizar es el número de individuos en la muestra. ¡Prueba en tu computador cambiando el número de árboles a estimar!</p>
</blockquote>
<div id="examinando-la-región-de-soporte-común" class="section level2">
<h2>Examinando la región de soporte común</h2>
<p>Un supuesto importante de la estimación en inferencia causal es que existe una región de soporte común. Esto es, que hay observaciones tratadas y no tratadas en la misma región. Para eso, estudiaremos el Propensity Score estimado por la función.</p>
<p>La predicción de Propensity Score queda guardado en la variable <em>W.hat</em>. En cambio, el valor real de los datos queda guardado en la variable <em>W.orig</em>. Utilizaremos el creador de gráficos <em>ggplot()</em> de la librería <em>ggplot2</em>. Se construyen gráficos tipo histograma y tipo densidad de kernel.</p>
<pre class="r"><code>ggplot(data.frame(W.hat = cf$W.hat, W = factor(cf$W.orig))) +
 geom_histogram(aes(x = W.hat, y = stat(density), fill = W), alpha=0.3, position = &quot;identity&quot;) +
 geom_density(aes(x = W.hat, color = W)) +
 xlim(0,1) +
 labs(title = &quot;Causal forest propensity scores&quot;,
      caption = &quot;The propensity scores are learned via GRF&#39;s regression forest&quot;)</code></pre>
<p>¿Existe región de soporte? (Sí)</p>
</div>
<div id="estudiando-la-heterogeneidad" class="section level2">
<h2>Estudiando la heterogeneidad</h2>
<p>Utilizaremos la misma muestra de entrenamiento para estudiar la heterogeneidad de los efectos, por ello, utilizaremos errores “out of the bag” (OOB) para validar los resultados. Utilizaremos la función <em>predict()</em>. Es también importante estimar los errores estándar de las predicciones, para examinar la significancia de ellas. Hay que recordar que las predicciones del CATE esperado se conocen como $() $, es decir, tau “gorro”, o tau “hat” en inglés.</p>
<pre class="r"><code>oob_pred &lt;- predict(cf, estimate.variance=TRUE)
oob_tauhat_cf &lt;- oob_pred$predictions
oob_tauhat_cf_se &lt;- sqrt(oob_pred$variance.estimates)</code></pre>
<blockquote>
<p>Para validar resultados utilizando el 20% de la muestra que quedó fuera, sólo se debe utilizar el parámetro <code>newdata =</code> en la función de predicción e incorporar allí la muestra de validación.</p>
</blockquote>
<p>Se debe evaluar entonces si es que existe heterogeneidad de los efectos. Para ello graficamos un histograma de las estimaciones del CATE esperado (o tau hat).</p>
<pre class="r"><code>hist(oob_tauhat_cf, main=&quot;Causal forests: out-of-bag CATE&quot;)</code></pre>
<p>¿Existe heterogeneidad? ¿Se concentra en efectos positivos, negativos o ambos?</p>
</div>
<div id="importancia-de-variables" class="section level2">
<h2>Importancia de Variables</h2>
<p>La función utilizada permite estudiar cuáles fueron aquellas variables que más afectaron la construcción de los árboles. Al promediar cuánto aporta cada variable en disminuir la suma de errores cuadrados o la impureza de las hojas, entonces se puede “rankear” la importancia de las variables.</p>
<pre class="r"><code>#Tabla
var_imp &lt;- c(variable_importance(cf))
names(var_imp) &lt;- colnames(as.data.frame(df_train %&gt;% select(-c(&quot;Y&quot;, &quot;W&quot;))))
sorted_var_imp &lt;- sort(var_imp, decreasing=TRUE)
head(sorted_var_imp, 15)</code></pre>
<blockquote>
<p>Es muy importante destacar que no sólo por estar abajo en el ranking de importancia quiere decir que una variable NO es importante para la heterogeneidad del efecto. Si dos variables tienen efectos importantes para la heterogeneidad, y tienen alta correlación entre ellas, puede ocurrir que el árbol utilice sólo una de ellas para la partición y no la otra, dejando a la primera alta en el ranking y a la segunda no.</p>
</blockquote>
</div>
</div>
<div id="heterogeneidad-en-subgrupos" class="section level1">
<h1><strong>5. Heterogeneidad en subgrupos</strong></h1>
<p>Para esto, generaremos <em>cuartiles</em> del efecto de tratamiento. Ordenando la muestra desde la observación con menor CATE esperado hasta la observación con mayor CATE esperado, dividiremos la muestra en cuatro, generándose así cuatro <em>cuartiles</em> de observaciones, y que, por lo tanto, son grupos que permiten una comparación con un adecuado poder estadístico. Para la generación de cuartiles, y la incorporación de una columna a nuestra base de datos de entrenamiento utilizamos la función <em>ntile()</em>. En este caso dividiremos la muestra en cuatro (cuartiles). Si dividiésemos la muestra en 5, serían quintiles.</p>
<pre class="r"><code>num_tiles &lt;- 4 
df_train$cate &lt;- oob_tauhat_cf
df_train$ntile &lt;- factor(ntile(oob_tauhat_cf, n=num_tiles))</code></pre>
<blockquote>
<p>Prueba cambiando el número de grupos de 4 a 5, y analiza cómo se modifican los resultados.</p>
</blockquote>
<p>Para estimar el efecto de tratamiento (ATE) en cada subgrupo se pueden utilizar dos métodos. El primero compara “en bruto” las diferencias de resultado entre tratados y controles. El segundo método construye un estimador robusto. En escenarios experimentales ambos métodos debiesen llevar a resultados similares, pero en datos observacionales el segundo método asegura estimaciones insesgadas y eficientes.</p>
<div id="sample-ate" class="section level2">
<h2>5.1. Sample ATE</h2>
<p>El primer método compara los efectos de tratamiento de tratados y de no tratados en cada uno de los cuartiles conformados. Para esto basta con realizar una regresión lineal (robusta), que nos permite a su vez estimar errores estandar. Esta regresión incluye términos de interacción con los indicadores de cada cuartil. La regresión con errores estándares robustos proviene de la función <em>lm_robust</em>, de la librería <em>estimater</em>.</p>
<pre class="r"><code>#Para hacer la estimación
ols_sample_ate &lt;- lm_robust(Y ~ ntile + ntile:W, data = df_train)

#Para que quede una tabla resumen con los resultados
estimated_sample_ate &lt;- coef(summary(ols_sample_ate))[(num_tiles+1):(2*num_tiles), c(&quot;Estimate&quot;, &quot;Std. Error&quot;)]</code></pre>
</div>
<div id="aipw-ate" class="section level2">
<h2>5.2. AIPW ATE</h2>
<p>El segundo método es el Augmented Inverse-Propensity Weighted ATE, o en español el ATE aumentado por ponderación de propensión inversa. Esto quiere decir que se ponderan las observaciones dentro de los cuartiles de acuerdo a (el inverso de) la probabilidad de haber sido tratados (Propensity Score). Esto debe hacerse por cada subgrupo.</p>
<pre class="r"><code>ateq1 &lt;-average_treatment_effect(cf,subset=df_train$ntile==1,method=&quot;AIPW&quot;)
ateq2 &lt;-average_treatment_effect(cf,subset=df_train$ntile==2,method=&quot;AIPW&quot;)
ateq3 &lt;-average_treatment_effect(cf,subset=df_train$ntile==3,method=&quot;AIPW&quot;)
ateq4 &lt;-average_treatment_effect(cf,subset=df_train$ntile==4,method=&quot;AIPW&quot;)
estimated_aipw_ate &lt;- data.frame(rbind(ateq1, ateq2, ateq3, ateq4))</code></pre>
<p>Veamos cómo se comparan los resultados de ambos métodos en este escenario (experimental):</p>
<pre class="r"><code>#Generando un data frame llamado G con columnas que indican el método y el cuartil de cada resultado:
  A &lt;- as.data.frame(estimated_sample_ate)
  B &lt;- as.data.frame(estimated_aipw_ate)
  colnames(A) &lt;- c(&quot;Estimate&quot;, &quot;Std. Error&quot;)
  colnames(B) &lt;- c(&quot;Estimate&quot;, &quot;Std. Error&quot;)
  G &lt;- rbind(A,B)
  G$method &lt;- c(1:8)
  G[1:4,]$method &lt;- &quot;Sample ATE&quot;
  G[5:8,]$method &lt;- &quot;AIPW ATE&quot;
  G$Cuartil &lt;- c(1:8)
  G[c(1,5),]$Cuartil &lt;- 1
  G[c(2,6),]$Cuartil &lt;- 2
  G[c(3,7),]$Cuartil &lt;- 3
  G[c(4,8),]$Cuartil &lt;- 4
    
ggplot(G, aes(x=Cuartil, y=Estimate, colour=method)) +
      geom_point(position=position_dodge(.9)) +
      geom_errorbar(aes(ymin=Estimate-(1.647 * `Std. Error`),
                        ymax=Estimate+(1.647 * `Std. Error`), colour=method), 
                        width=.2,position=position_dodge(.9)) +
       theme(legend.title = element_blank(),panel.grid.major = element_blank()) +
       labs(x=&quot;Conditional Average Treatment Effect&quot;, #xlab() agrega etiqueta del eje X
       y=&quot;Frecuencia&quot;, #ylab() agrega etiqueta del eje y
       title=&quot;ATE en subgrupos&quot; )</code></pre>
<p>¿Se puede concluir que existen diferencias significativas en los ATE entre algunos grupos?</p>
</div>
</div>
<div id="blp" class="section level1">
<h1><strong>6. BLP</strong></h1>
<p>Una forma de estudiar la variación del efecto de tratamiento es a través de la estimación del Best Linear Projection (o Best Linear Predictor). Este estudio permite, por un lado, evaluar la significancia de la heterogeneidad encontrada, a partir de un test motivado por Chernozhukov, Demirer, Duflo &amp; Fernandez-Val (2018).</p>
<div id="test-de-calibración" class="section level2">
<h2>Test de calibración</h2>
<p>El test consiste en utilizar un estimador que corrige la BLP de acuerdo a su Propensity Score y a los valores esperados. Para ver en detalle la forma del estimador, pueden dirigirse al artículo original de Chernozhukov et al. (2018), al Tutorial de Athey y colegas (2020), o al artículo de Murakami et al. (2020). Lo importante es tener en mente que se estima una regresión del estilo</p>
<p><span class="math display">\[Y_i - \hat{Y_i} = \alpha  \cdot \hat{ATE} + \beta \cdot \hat{\tau_i}(x) + \varepsilon_i \]</span></p>
<p>donde las hipótesis nulas i) <span class="math inline">\(\alpha = 0\)</span> indica que el valor del efecto de tratamiento para toda la muestra no es diferente de cero, y ii) <span class="math inline">\(\beta = 0\)</span> no existe heterogeneidad en el efecto de tratamiento. De forma particular, en términos del ajuste del módelo, y siguiendo a Athey y colegas (2020), si es que <span class="math inline">\(\alpha = 1\)</span> entonces la predicción promedio del ATE es adecuada, y si <span class="math inline">\(\beta = 1\)</span> entonces las predicciones del Causal Forest capturan la heterogeneidad subyacente de forma adecuada.</p>
<pre class="r"><code>tc &lt;- test_calibration(cf)
tc</code></pre>
</div>
<div id="interpretaciones" class="section level2">
<h2>Interpretaciones</h2>
<p>Para estudiar el efecto de tratamiento con una covariable en particular, se puede utilizar la función <em>best_linera_projection()</em> para ver la magnitud de las pendientes. En este caso comenzaremos con la variable que indica si el sujeto en estudio está divorciado o no. ¿Cómo se interpreta este resultado?</p>
<pre class="r"><code>best_linear_projection(cf, df_train$divorce)</code></pre>
<blockquote>
<p>Prueba con otras covariables, puedes comenzar por aquellas que están en los primeros lugares del ranking de importancia.</p>
</blockquote>
</div>
<div id="optimización" class="section level2">
<h2>Optimización</h2>
<p>Entendiendo que las Best Linear Projection permite estudiar que el efecto de tratamiento varía con una determinada covariable: ¿cómo se interpretaría la heterogeneidad del efecto estudiado en este caso para las variables que escogiste? Este estudio de caso no es una programa o política pública determinada, sino que es un tratamiento experimental para evaluar las percepciones sobre las políticas de bienestar.</p>
<p>En cambio, si estuvieramos estudiando una política o programa, sería de interés poder diseñar un óptimo.</p>
<blockquote>

</blockquote>
<div id="chernozhukov-v.-demirer-m.-duflo-e.-fernandez-val-i.-2018.-generic-machine-learning-inference-on-heterogeneous-treatment-effects-in-randomized-experiments-with-an-application-to-immunization-in-india-no.-w24678.-national-bureau-of-economic-research." class="section level6">
<h6>Chernozhukov, V., Demirer, M., Duflo, E., &amp; Fernandez-Val, I. (2018). Generic Machine Learning Inference on Heterogeneous Treatment Effects in Randomized Experiments, with an Application to Immunization in India (No. w24678). National Bureau of Economic Research.</h6>
</div>
<div id="murakami-k.-shimada-h.-ushifusa-y.-ida-t.-2020.-heterogeneous-treatment-effects-of-nudge-and-rebate-causal-machine-learning-in-a-field-experiment-on-electricity-conservation-no.-e-20-003." class="section level6">
<h6>Murakami, K., Shimada, H., Ushifusa, Y., &amp; Ida, T. (2020). Heterogeneous Treatment Effects of Nudge and Rebate: Causal Machine Learning in a Field Experiment on Electricity Conservation (No. e-20-003).</h6>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
